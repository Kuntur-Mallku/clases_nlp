{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f19747c7-e8de-41d2-9b7c-e61f9cc64f6f",
      "metadata": {
        "id": "f19747c7-e8de-41d2-9b7c-e61f9cc64f6f"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7bdf56f9-5b88-4a00-8327-3f7a4bec3183",
      "metadata": {
        "id": "7bdf56f9-5b88-4a00-8327-3f7a4bec3183"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/home/kmuenala/nlp\")"
      ],
      "metadata": {
        "id": "gfD2sPCeVFD_"
      },
      "id": "gfD2sPCeVFD_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "434ffc33-1973-479c-bc9e-2638e7dfaabe",
      "metadata": {
        "id": "434ffc33-1973-479c-bc9e-2638e7dfaabe"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "46f0a794-4699-44c5-bf4c-00e2b80dc36c",
      "metadata": {
        "id": "46f0a794-4699-44c5-bf4c-00e2b80dc36c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_layers):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        memory = self.transformer_encoder(src)\n",
        "        return memory\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2d96118f-f5c8-4061-ab13-61f84ccb6177",
      "metadata": {
        "id": "2d96118f-f5c8-4061-ab13-61f84ccb6177"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, output_size, d_model, nhead, num_layers):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        decoder_layers = nn.TransformerDecoderLayer(d_model, nhead)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, output_size)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "        output = self.transformer_decoder(tgt, memory)\n",
        "        output = self.fc_out(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Definir los hiperparámetros\n",
        "INPUT_SIZE = input_lang.n_words  # Número de palabras en el vocabulario del idioma fuente\n",
        "OUTPUT_SIZE = output_lang.n_words  # Número de palabras en el vocabulario del idioma destino\n",
        "D_MODEL = 512  # Dimensión de los embeddings y del modelo\n",
        "NHEAD = 8  # Número de cabezas de atención\n",
        "NUM_LAYERS = 6  # Número de capas de codificador/decodificador\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 10  # Longitud máxima de las oraciones\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 10\n",
        "\n",
        "# Inicializar Encoder y Decoder basados en Transformer\n",
        "encoder = TransformerEncoder(INPUT_SIZE, D_MODEL, NHEAD, NUM_LAYERS).to(device)\n",
        "decoder = TransformerDecoder(OUTPUT_SIZE, D_MODEL, NHEAD, NUM_LAYERS).to(device)\n",
        "\n",
        "# Definir optimizadores\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Definir la función de pérdida (Cross Entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Función de entrenamiento\n",
        "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Paso de codificación (encoder)\n",
        "    encoder_outputs = encoder(input_tensor)\n",
        "\n",
        "    # Inicializar el primer token para el decodificador (comienza con SOS)\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    for t in range(target_length):\n",
        "        decoder_output = decoder(decoder_input, encoder_outputs)\n",
        "        topv, topi = decoder_output.topk(1)  # Obtener la palabra con la mayor probabilidad\n",
        "        decoder_input = topi.squeeze().detach()  # Actualizamos el input del decodificador\n",
        "\n",
        "        # Calcular la pérdida\n",
        "        loss += criterion(decoder_output, target_tensor[t].unsqueeze(0))\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los pesos de encoder y decoder\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "# Función para entrenar el modelo por múltiples épocas\n",
        "def train(encoder, decoder, n_epochs, print_every=1000):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        total_loss = 0\n",
        "\n",
        "        # Recorrer el dataset y entrenar\n",
        "        for i, (input_tensor, target_tensor) in enumerate(data_loader):\n",
        "            loss = train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, MAX_LENGTH)\n",
        "            total_loss += loss\n",
        "\n",
        "            if i % print_every == 0:\n",
        "                print(f\"Epoch {epoch} - Step {i} - Loss: {loss}\")\n",
        "\n",
        "        print(f\"Epoch {epoch} - Average Loss: {total_loss / len(data_loader)}\")\n",
        "\n",
        "# Función de evaluación\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang, max_length):\n",
        "    with torch.no_grad():\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "\n",
        "        # Codificar la oración de entrada\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        encoder_outputs = encoder(input_tensor)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoded_words = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            decoder_output = decoder(decoder_input, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return ' '.join(decoded_words)\n",
        "\n",
        "# Entrenar el modelo\n",
        "train(encoder, decoder, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "xEquopWGS6Tz",
        "outputId": "123b6758-6bc1-44b0-8302-6ac5a6103fb9"
      },
      "id": "xEquopWGS6Tz",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tensorFromSentence() takes 2 positional arguments but 3 were given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4970d4da1bf3>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# Entrenar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-4970d4da1bf3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, n_epochs, print_every)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Recorrer el dataset y entrenar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6e8c488d777a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Convertir las oraciones en tensores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tensorFromSentence() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50efa0e9-4e6d-4a05-a59a-a2bbbef2c6e8",
      "metadata": {
        "id": "50efa0e9-4e6d-4a05-a59a-a2bbbef2c6e8"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b47802-aa08-4188-93cf-d4b14c0c1a9c",
      "metadata": {
        "id": "d9b47802-aa08-4188-93cf-d4b14c0c1a9c"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d50ab216-0589-4f6e-9a28-7e296ef5b1e7",
      "metadata": {
        "id": "d50ab216-0589-4f6e-9a28-7e296ef5b1e7"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def filterPair(p):\n",
        "    try:\n",
        "        return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "            len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
        "#            p[0].startswith(eng_prefixes)\n",
        "    except:\n",
        "        print(p)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b7e2d0e-6cbd-4cd1-bc2e-d33b11be7fba",
      "metadata": {
        "id": "5b7e2d0e-6cbd-4cd1-bc2e-d33b11be7fba"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b6aa2545-d18d-494a-a696-d553bab728b9",
      "metadata": {
        "id": "b6aa2545-d18d-494a-a696-d553bab728b9"
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2, file):\n",
        "    text = open(file, encoding='utf-8').read().split('\\n')\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in text ]\n",
        "    pairs = [pair for pair in pairs if len(pair) == 2]\n",
        "\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "    pairs = filterPairs(pairs)\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee09220c-5d9a-46c2-89f8-064b0fc28f63",
      "metadata": {
        "id": "ee09220c-5d9a-46c2-89f8-064b0fc28f63"
      },
      "outputs": [],
      "source": [
        "path = \"./models/\"\n",
        "encoder = torch.load(path+\"translate_sp_en_encoder.pt\")\n",
        "decoder = torch.load(path+\"translate_sp_en_decoder.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "afaf3c7e-3ea0-4b96-8ef0-1cf98d8b39a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afaf3c7e-3ea0-4b96-8ef0-1cf98d8b39a4",
        "outputId": "bfb29710-3f27-448e-b6c7-412276d158ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "eng 12105\n",
            "spa 23411\n"
          ]
        }
      ],
      "source": [
        "file = 'data/spa.txt'\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'spa', file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs, input_lang, output_lang, max_length=10):\n",
        "        self.pairs = pairs\n",
        "        self.input_lang = input_lang\n",
        "        self.output_lang = output_lang\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_sentence, target_sentence = self.pairs[idx]\n",
        "\n",
        "        # Convertir las oraciones en tensores\n",
        "        input_tensor = tensorFromSentence(self.input_lang, input_sentence, self.max_length)\n",
        "        target_tensor = tensorFromSentence(self.output_lang, target_sentence, self.max_length)\n",
        "\n",
        "        def indexesFromSentence(lang, sentence):\n",
        "            return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "        def tensorFromSentence(lang, sentence):\n",
        "            indexes = indexesFromSentence(lang, sentence)\n",
        "            indexes.append(EOS_token)\n",
        "            return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "        def tensorsFromPair(pair):\n",
        "            input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "            target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "            return (input_tensor, target_tensor)\n",
        "\n",
        "        return input_tensor, target_tensor\n"
      ],
      "metadata": {
        "id": "nHbqwpbOYfbs"
      },
      "id": "nHbqwpbOYfbs",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un dataset\n",
        "dataset = TranslationDataset(pairs, input_lang, output_lang, max_length=MAX_LENGTH)\n",
        "\n",
        "# Crear un DataLoader\n",
        "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "SsrZpXXOYtNC"
      },
      "id": "SsrZpXXOYtNC",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbf8658-2080-4242-b6cf-e92aeb2b5239",
      "metadata": {
        "id": "fbbf8658-2080-4242-b6cf-e92aeb2b5239",
        "outputId": "9a51beb8-737d-4425-bd40-c876801f03bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> that wasn t my fault\n",
            "= eso no fue mi culpa\n",
            "< no fue mi culpa mia <EOS>\n",
            "\n",
            "> please smile\n",
            "= sonreid\n",
            "< favor le puso gasolina en las armas <EOS>\n",
            "\n",
            "> she s at a meeting\n",
            "= ella esta en una reunion\n",
            "< ella es un aliado en la reunion <EOS>\n",
            "\n",
            "> you learn something new every day\n",
            "= cada dia aprendes algo nuevo\n",
            "< aprendiste un nuevo dia de ingles <EOS>\n",
            "\n",
            "> this machine can print sixty pages a minute\n",
            "= este aparato puede imprimir sesenta paginas por minuto\n",
            "< este aparato puede imprimir sesenta paginas por minuto <EOS>\n",
            "\n",
            "> is this price acceptable ?\n",
            "= es aceptable el precio ?\n",
            "< es aceptable el precio de la mia ? <EOS>\n",
            "\n",
            "> why are you wearing my coat ?\n",
            "= por que estas usando mi abrigo ?\n",
            "< por que lleva usted mi abrigo ? <EOS>\n",
            "\n",
            "> tom was just as scared as mary was\n",
            "= tom estaba tan asustado como lo estaba mary\n",
            "< tom estaba tan asustado como lo estaba mary <EOS>\n",
            "\n",
            "> this was his one and only hope\n",
            "= esta era su unica esperanza\n",
            "< era su unica parque solo tiene una necesidad urgente <EOS>\n",
            "\n",
            "> did you already do your homework ?\n",
            "= ya hiciste tu tarea ?\n",
            "< ya hiciste tu tarea ? <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa9cfcc-c904-4110-99db-72574959988c",
      "metadata": {
        "id": "cfa9cfcc-c904-4110-99db-72574959988c",
        "outputId": "1dedec87-3a47-4c06-8a70-8115a1282dd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['ella', 'es', 'mi', 'hermana', 'mayor', '<EOS>'], None)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'she is my sister', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce722b4-3454-4eac-a897-f30a68c0ee28",
      "metadata": {
        "id": "2ce722b4-3454-4eac-a897-f30a68c0ee28",
        "outputId": "e4c8d9b7-bd1a-47c8-9535-1e97b870e512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['estoy', 'contento', 'de', 'mi', 'casa', 'es', 'verde', '<EOS>'], None)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'i am cleaning my house', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3784c171-72dd-437d-8ade-1059865f3ba3",
      "metadata": {
        "id": "3784c171-72dd-437d-8ade-1059865f3ba3",
        "outputId": "bea97a09-0f7c-49bb-fcd4-5b6697fee820"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['cuando', 'puedo', 'hacer', 'los', 'documentos', '?', '<EOS>'], None)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'when is homework due ?', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "905d6f11-3ee3-4028-baa3-fdee8e0a1a06",
      "metadata": {
        "id": "905d6f11-3ee3-4028-baa3-fdee8e0a1a06",
        "outputId": "7341a43f-a8c9-40af-8339-c027734c9d4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['tengo', 'miedo', 'de', 'tener', 'miedo', '<EOS>'], None)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'i m scared', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21926b7d-4180-4fbb-9700-9247b5072473",
      "metadata": {
        "id": "21926b7d-4180-4fbb-9700-9247b5072473",
        "outputId": "904c1e31-22ca-4875-db6f-eee95e77e84c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['como', 'se', 'llama', 'mi', '?', '<EOS>'], None)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'what is my name ?', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06563b6f-514b-4157-bba6-5f5e45f2a236",
      "metadata": {
        "id": "06563b6f-514b-4157-bba6-5f5e45f2a236",
        "outputId": "5f72f790-ecc4-4d70-aec9-13f80f73179f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['cual', 'es', 'tu', 'nombre', '?', '<EOS>'], None)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'what is your name ?', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082f0e28-766f-4f88-abef-aee32a4d61a7",
      "metadata": {
        "id": "082f0e28-766f-4f88-abef-aee32a4d61a7",
        "outputId": "16a476ef-746f-4c4c-b1f6-3dbebfd98ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['como', 'se', 'llama', 'tu', 'nombre', '?', '<EOS>'], None)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'what is her name ?', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd99f77-e71b-4caa-b0a0-bdbf17ab9c1c",
      "metadata": {
        "id": "bbd99f77-e71b-4caa-b0a0-bdbf17ab9c1c",
        "outputId": "64ed235e-a69e-4603-ba20-00329117ba11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['como', 'se', 'llama', 'tu', 'nombre', '?', '<EOS>'], None)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'what is his name ?', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6850cf63-2018-4ca1-893c-9469ca7bae79",
      "metadata": {
        "id": "6850cf63-2018-4ca1-893c-9469ca7bae79",
        "outputId": "e66c6854-abbe-4259-a2ec-aae433a929ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['muchos', 'anos', 'mas', 'lejos', 'mucho', '<EOS>'], None)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'many years later', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8544a22d-dc60-4d25-97d2-9b49f9f0e873",
      "metadata": {
        "id": "8544a22d-dc60-4d25-97d2-9b49f9f0e873",
        "outputId": "bea3eb0f-daad-478e-9eaa-e37f85320c6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['estoy', 'bebiendo', 'un', 'vaso', 'de', 'ingles', '<EOS>'], None)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'i m taking an english class', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a51f277b-1239-4b56-af14-e1c80ac07da8",
      "metadata": {
        "id": "a51f277b-1239-4b56-af14-e1c80ac07da8",
        "outputId": "5a3ad2e6-0799-48c5-e695-e3e12f82c778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['estoy', 'estudiando', 'ingles', 'en', 'el', 'estudio', '<EOS>'], None)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'i m studying in an english class', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b55c790-04d8-47c4-b53e-039cfa998e72",
      "metadata": {
        "id": "3b55c790-04d8-47c4-b53e-039cfa998e72",
        "outputId": "6080b0c0-39ab-46cd-cdbb-2a48fe996b98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['juegan', 'al', 'futbol', 'al', 'futbol', '<EOS>'], None)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'they play soccer', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c52a1d-4510-4193-99af-b58a8f4cb6f1",
      "metadata": {
        "id": "14c52a1d-4510-4193-99af-b58a8f4cb6f1"
      },
      "outputs": [],
      "source": [
        "play v. -> jugar\n",
        "play n. -> actividad de entretenimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55d7a5a-d4c5-4bd8-b91c-25b50283899a",
      "metadata": {
        "id": "d55d7a5a-d4c5-4bd8-b91c-25b50283899a",
        "outputId": "9a052089-3236-4c18-b8ee-183281f2bd31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['mi', 'hermano', 'nunca', 'se', 'fue', 'en', 'mi', 'fiesta', '<EOS>'], None)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder, decoder, 'my brother never showed up in my party', input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee5cd84-9b51-4dff-b417-735f5b892b9f",
      "metadata": {
        "id": "2ee5cd84-9b51-4dff-b417-735f5b892b9f"
      },
      "outputs": [],
      "source": [
        "path = \"./models/\"\n",
        "encoder_attn = torch.load(path+\"translate_sp_en_attn_encoder.pt\")\n",
        "decoder_attn = torch.load(path+\"translate_sp_en_attn_decoder.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d944ebc-f69d-4b35-9b1e-7862e2e7aa26",
      "metadata": {
        "id": "8d944ebc-f69d-4b35-9b1e-7862e2e7aa26",
        "outputId": "20218460-0396-4f5a-b64a-dda27ad8feba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ella', 'es', 'mi', 'hermana', 'llamado', '<EOS>']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(encoder_attn, decoder_attn, 'she is my sister', input_lang, output_lang)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119c4f16-ec11-4dca-b73f-358421ef40e5",
      "metadata": {
        "id": "119c4f16-ec11-4dca-b73f-358421ef40e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}